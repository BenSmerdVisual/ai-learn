- **Search problem**- using searching techniques to achieve a result--like a puzzle
- **Agent**- entity that perceives an environment and can act on that environment through actions
- **State**- a configuration of the agent in the evironment- kind of the different steps of getting from the *initial state* to the *final state*, what actions need to be applied from the initial to get to the goal (end)
- **Actions**- choices that are made in a state- can be seen a sfunction that takes a state as parameter and within the function an action is acted upon the state for the state to be updated to the next state
- **Transition model**- the description of what state results from performing a applicable state on it- the function of result takes a state and action as parameters and returns the state reslting from the performance of the action
- **State space**- the set of all states reachable from the initial state by any sequence of actions- basically all the outcomes that can happen from acting any action on the state (all possibilities)
- **Goal test**- way to determine whether a given state is a goal state- determine that the current state of the probleem is the state equaling that the goal has been achieved- there may be mutliple goals or singular
- **Path cost**- numeraical cost associated with a given path- basically the measurement to assess how one path from initial to goal is bettter than another one, based on the cost of the numerical measurement associated (km traveled in a route mapper)
- **Optimal solution**- the best way to get from initial state to goal state that has the most optimal path cost compared to other paths
- **Node**- data structure that will keep track of: state, parent (state/node before this current node), action (the action applied to the parent to get to current node), path cost (from initial state to the current node)
- Options arise once the state is acted upon by a certain action and then we can see what the optuons have arisen based on that action and can progress to the next
- **Approach**- 
	- Start with a frontier that contains the intiial state
	- Repeat- if frontier is empty then no solution otherwise remove a node from the frontier, if the frontier node contains the goal state, then we found the solution (using checks) and it is done
	- The frontier gets updated when the current node has been checked as the only one that works from the initial state and it ISNT the goal node
	- Can have multuiple nodes in the frontier if they are children of the most optimal node from the initial node state
	- Can also go in both directions from node to node if need to
- **Revised Approach**- 
	- Start with frontier containing initial state
	- Start with an empty explored set
	- Repeat- if frontier is empty = no solution, remove node from frontier, if node contains goal state then = solution, add node to explored set
	- Use a stack- **depth-first-search** (last in, first out) data type--- this is good to traverse a path until there is no result, and then can traverse the alternative paths as they are next in line, because the latest in will be first out for each pathway node--- potential more saving in memory as it doesnt cover everything to find the solution, hpowever it may have to go through every branch before it can find the solution wghich could be costly
	- Use a queue- **breadth-first-search** (first in first out data type)-- this traverses the paths by each sequential node so each branch will go by at a node of each branch at a time, rather where the stack goes a full branch at a time, the queue goes a section of the branch and then the next section of a branch and back to the other branch and next section etc-- could be very cost heavy as it may cover almost every single option, however it may hit the solution earlier because it increments all branches and the solution may be short
- **Uninformed Search**- search strategies that use no specific knowledge for the problem, it is just a sort of a "do as you go" type search- how the depth-first-search and breadth-fiest-search are as they are a check each node and if its right its right type of search

## Informed Search
- **Informed search**- using knowledge sepcific to the problem to find a solution
- **Greedy best-first search**- search algorithm that expands the node that is closes to the goal as estimated by heuristic function h(n) (estimating how close we are to the goal)
	- **Manhatten distance**- geographically determine how close a node is to the goal, so can take an estimate for which node is closer to the goal than others geographically
		- Using the guessing of each node as to how far they from the goal, you can use that to determine which is the next node (as you would choose the next node that is closer to the goal based on the heuristic estimation)- this is a more informed decision as you would most likely choose the closer node--can obviously be wrong rhough as geographically the guess may not take into account obstacles as obstacles may not be present
		- Because its greedy it means that it chooses the best solution at present without taking other things into cosidertion (eg choosing the closes node next without taking into account obstacles)
- **A* search**- Search algorithm that expands node with loest value g(n) + h(n), g(n) = cost to reach node, h(n) = estimated cost to goal
	- Combining the cost of how many steps to reach the goal and the heuristic estimate away from the goal to determine most optimal soltuon--- adding the steps taken and whats left to find the least
	- Can find the way for the most optimal which couyld be the shortest and then as soon as that path starts getting more steps than any previous splits in the road, it can start taking the other path as it may now be less steps that the currently taken path (this helps if a path seemed shorter at first but then starts to become further)--- good at stopping a path before it gets too long-- however can end up covering a lot of ground
- **Adversial Search**- when there are competing moves to reach a goal
	- **Minimax**- Where there are 3 outcomes- (-1 = player 1 wins, 0= draw, 1 = player 2 wins)
		- MAX- player 2 is trying to maximize the score (>=1 = they win)
		- MIN- player 1 is trying to minimise the score (<=-1 = they win)
		- Kind of like a tree with each branch offering the potential move scores
		- Each turn the AI for each player will calculate the current state and then the future state if they move in that spot in tic-tac-to and if they are closer to their score direction then they will play that move, if its further from their score direction they will not play that move--- kind of seeing the move and then what can happen next and then making the correct chocie to be CLOSER to their score direction (rather draw=0 THAN lose=opposite direction)
		- Essentially its assessing the current STATE of the game and viewing what the next possible STATE potentials are and then seeing if they are allowing for a loss or draw (draw state is favourable for opening rounds as well) but MAINLY looking for the potential path on the branch which goes more in their score direction (positive or negative)
		- **Optimisation**- looking at two layers deep as to what the next players most optimal choice (based on the best scenario) then can determine what the current players best choice is as well
			- Optimsing even more is by being able to check a branch based on its earlier choices if they are alreadyy better than the previous branch
			- **Alpha-Beta pruning**- getting rid of branches earler by comparing the choice before traversing that branch completely, based on the rpevious branch, this eliminates having to go through everything
	- **Depth-limited minimax**- not looking unlimited potential moves ahead, it looks a specific amount ahead- saves ALOT of computation and time