## What is Generative AI
- AI similar to chatGPT
- **Generatve AI**- produce high quality content, specifically text, images and audio
- Becoming a lot cheaper to build AI applications
- **How it works**- You can have supervised learning (labelling the input for a specific output)
	- Generative AI is separate from supervised, unsupervised and reinforcement learning
	- Genereative AI is built from supervised learning- still needs large amounts of data similar to the supervised learning
	- **Large Language Models (LLMs)**- text generation process being able to create sentences
		- Using supervised learning to repeatedly predict the next word by having many input and being able to identify the most relevant output based on the dataset
		- Using a lot of data there is hundreds of billions of word variances
		- **hallucination**- LLM can make up information to fit the need to return an output- can also sound really certain on the answer even though it is wrong which an decieve the user
- **General purpose**- 
	- Good for writing coherent explanations and ideas based on the prompt- also really good for translating languages (but struggles a bit with more context of languages and slang/formal words) 
	- Can read text to be able to provide a response for something like a summary in certain amount of words, semantic observation- it can proofread over some information and make sure the english asnd spelling is correct- being able to read the message from someones and then determine which department or person is best suited to answer the message- good for analysing the messages and then being also able to provide analytical visualisaton based on the observation from the LLM analysis
	- Chatting to be able to have conversation with a user, especially for things like taking orders or providing even more information after a chat has more details given throughout the chat- specialisation chatbot can help by having specific knowledge about a certain domain (travel, sports etc) and it gets all its data just on those domains- can have *human-in-the-loop* for a chatbot cycle as they can read over the chat created by the chatbot to make sure it's correct information- can also use the robots for triaging to sort the requests to go to specific people/bots
- **What LLMs can and cant do**- the expectations and limitations
	- **Can**- Give more detail about a specific context as it has more knowledge than a human on certain topic
		- Works best with unstructured data as these are text, images, audio, video
	- **Can't**- There is knowledge cutoffs as the amount of data can be only up to a specific date, and anything afer that date it would not know about it. LLM can make up things *hallucinations* to just provide a response to the user and makes it seem like it is real through how it presents its information
		- THe content length of the input and output is limited, so this results in more separate prompting which may ruin the context of the overall problem wanting to be solved
		- Doesn't work well with strucured (tabular) data as an input if it isn't specific enough
		- LLM can produce Bias and toxicity which is based on the internet stereotypes and this can be negative and toxic
- **Image generation**- 
	- **Diffusion Model (supervised learning)**- find pictures of the specific input (apple, cat etc) and uses them as their data with the label of each object
		- Gradually removes any picture noise to be able to create a clearer picture based on the data set by constantly updating the picture by removing the noise and working its way to a clearer picture
- **Software applications using generative AI**- Being able to produce chat like machine learning that can talk to the user about input data, rather than using chatgpt for general, making it more specific to a buiness
	- Using things like a prompt based development, can use a trained model that can see the sentiment based on general words to determine if positive or negative, rather than having to build own sort of business based sentiment analyzer
	- Important in the lifecycle of generative AI process to return feedback where a prompt may be incorrect and then use that inorrect output to improve the input/ouput and train more from it
	- **Cost intuition using LLM**- 
		- **Token**- a part of text which is important- names or adverds, sometimes parts of words program-ming split into 2 tokens: this is how the LLM can differentiate the words and do algorithms on them
	- **Methods beyond regular prompting**
		- **Retrieval Augmented Generation (RAG)**- Giving the LLM more information from your company to be able to search that information- and then incorporating the returned text into an updated prompt- this updated prompt them goes into the LLM where the prompt will have first part "use this text to answer the question at end--- {insert text back from the document} {insert users prompt question}" - maybe the specific section or a summary of that block of text
		- **Fine-Tuning**- Having done the pretraining (input the training data to be able to have labels so can have outputs match the input based on the label). **fine tuning** is using a smaller data set to be able to fine tune something if it requires extremely specific sort of output, you dont want massive data sets that can provide responses that may not be relevant to context
			- Good for if you want specific sort of summaries or structure in  specific style. Just specifying the LLM to be specific
			- Good for if the task is more complex than just writing a simple prompt to then sift through a lot of data to provide a response, while the fine tuning doesnt as heavily rely on such a specific prompt
			- Be trained on extremely specific knowledge- things like business jargon (coding for example has specific jargon and key words)
		- **Pretraining own LLM**- Usually big companies do it but are very expensive
			- Take a lot of money, time and data and opensource has helped push these along for specific domains
		- **Choosing an LLM**- The larger the parameter LLM size means it has wider knowledge of the world and can provide more wide variety in information and specificity
	- **How LLM learn to follow instructions and not just provide text back**- 
		- Can train the LLM on specific responses to specific input
		- **Reinforcement learning from human feedback (RLHF)**- Helpful, honest and harmless- Train answer quality reward model- Receive responses and determine BY HUMANS if they are good responses that were actually helpful in a real human scenario. Then get it training on a lot more responses that get high scores
			- It is training on responses that humans gave feedback to as being good or bad- provide a reinforcement cycle of doing it 
	- **Tools and agents used**- 
		- Not good at precise maths, so can use a CALCULATOR tool to do the maths
		- Can use agentst to breakdown individual tasks (like searching a website, booking a ticket etc) through separate APIs
- **Generative AI in business**- 
	- Automating tasks that can replace tedious smaller tasks that humans do
	- Augmentation by helping humans with tasks
- **Generative AI in society**-
	- Does have bias based off the training data- especially if it's based off the internet
	- important to do the RLHF to reduce any bias information
- **Artifitial general intelligence (AGI)**- AI that can do any intellectual task that a human can do eg driving a car, painting a picture like a human
	- Essentially be able to create an idea and then do the same how humans do it where they work with the idea in some sort of action (painting, creating, researching etc)
- **Build more intelligent world**- using AI to build a better world with more intelligence